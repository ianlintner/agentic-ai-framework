# Default telemetry configuration for the Agentic AI Framework

telemetry {
  # Name of the service for identification in telemetry systems
  service-name = "agentic-ai-service"
  
  # Sampling ratio for traces (0.0-1.0)
  # - 1.0: Record all traces
  # - 0.5: Record 50% of traces
  # - 0.0: Don't record any traces
  sampling-ratio = 1.0
  
  # Exporter configurations
  exporters {
    # Prometheus metrics exporter
    prometheus {
      enabled = true
      port = 9464
    }
    
    # Jaeger distributed tracing exporter
    jaeger {
      enabled = true
      endpoint = "http://localhost:14250"
    }
    
    # OpenTelemetry Protocol (OTLP) exporter for general compatibility
    otlp {
      enabled = true
      endpoint = "http://localhost:4317"
    }
    
    # Console logging for debugging and development
    console {
      enabled = true
    }
  }
  
  # Custom metrics configurations
  metrics {
    # LLM-specific metrics
    llm {
      # Track token usage and costs
      token-tracking = true
      # Default cost per 1000 tokens (in USD)
      default-cost-per-1k-tokens = 0.002
    }
    
    # Agent metrics
    agent {
      # Track agent execution times
      execution-timing = true
      # Track memory usage
      memory-tracking = true
    }
    
    # Mesh metrics
    mesh {
      # Detailed message tracking
      detailed-message-tracking = true
      # Track node health metrics
      node-health-monitoring = true
    }
  }
}